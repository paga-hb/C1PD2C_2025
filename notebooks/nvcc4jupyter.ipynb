{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa91693",
   "metadata": {},
   "source": [
    "# nvcc4Jupyter\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/paga-hb/C1PD2C_2025/blob/main/notebooks/nvcc4jupyter.ipynb)\n",
    "\n",
    "This notebook shows how to use the nvcc4Jupyter extension.\n",
    "\n",
    "- GitHub: https://github.com/andreinechaev/nvcc4jupyter\n",
    "- Docs: https://nvcc4jupyter.readthedocs.io/en/latest\n",
    "\n",
    "Requirements for nvcc4jupyter to work:\n",
    "\n",
    "- NVIDIA GPU + Drivers (runtime)\n",
    "  - You need a supported NVIDIA GPU and the appropriate driver version installed to actually run the CUDA code.\n",
    "- CUDA Toolkit\n",
    "  - Includes nvcc (the NVIDIA CUDA Compiler).\n",
    "  - Provides headers and libraries needed for compiling GPU code.\n",
    "  - Must be compatible with your system's GPU drivers.\n",
    "- C/C++ Compiler\n",
    "  - On Linux: usually g++ or clang++.\n",
    "  - On Windows: MSVC (Microsoft Visual C++) or WSL with Linux tools.\n",
    "  - On macOS: CUDA isn't officially supported for newer GPUs, so this is trickier.\n",
    "\n",
    "What nvcc4jupyter does\n",
    "- It lets you write CUDA C++ code in a Jupyter cell using a magic like `%%cuda`.\n",
    "- It compiles the code using nvcc on your local machine.\n",
    "- It then runs the compiled binary and shows the output in the notebook.\n",
    "\n",
    "That means all the compilation and execution happens locally, so you need the full CUDA development environment.\n",
    "- Common issues if something’s missing:\n",
    "  - nvcc: command not found → CUDA Toolkit isn't installed or not in PATH.\n",
    "  - iostream: No such file or directory → Missing C++ compiler.\n",
    "  - cuda_runtime.h: No such file or directory → CUDA Toolkit headers not found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31675ec6",
   "metadata": {},
   "source": [
    "---\n",
    "## Install and Load `nvcc4jupyter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41853651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvcc4jupyter in ./.conda/lib/python3.12/site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd32a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
      "  %reload_ext nvcc4jupyter\n",
      "Source files will be saved in \"/tmp/tmp4my8x1vf\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter\n",
    "%reload_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b4113",
   "metadata": {},
   "source": [
    "---\n",
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "231f2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "\n",
    "int main()\n",
    "{\n",
    "    printf(\"Hello World!\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96cff67",
   "metadata": {},
   "source": [
    "---\n",
    "## C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d6c1512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main()\n",
    "{\n",
    "    cout << \"Hello World!\" << endl;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa3231",
   "metadata": {},
   "source": [
    "---\n",
    "## CUDA C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc3f4ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from host\n",
      "Hello from device -> block: 1, thread: 0\n",
      "Hello from device -> block: 1, thread: 1\n",
      "Hello from device -> block: 0, thread: 0\n",
      "Hello from device -> block: 0, thread: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void hello()\n",
    "{\n",
    "    // CUDA supports the printf() function on the device\n",
    "    printf(\"Hello from device -> block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    printf(\"Hello from host\\n\");\n",
    "    hello<<<2, 2>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34858977",
   "metadata": {},
   "source": [
    "---\n",
    "## CUDA C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc64f4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from host\n",
      "Hello from device block: 1, thread: 0\n",
      "Hello from device block: 1, thread: 1\n",
      "Hello from device block: 0, thread: 0\n",
      "Hello from device block: 0, thread: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void hello()\n",
    "{\n",
    "    // Note! CUDA does NOT support cout on the device (so use printf() for debugging)\n",
    "    printf(\"Hello from device block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    // It's fine to use cout on the host\n",
    "    cout << \"Hello from host\" << endl;\n",
    "    hello<<<2, 2>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0f2883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements: 7\t10\t9\t7\t5\t7\t10\t0\t9\t1\t2\t7\t\n",
      "The largest element is: 10\n",
      "The time required: 0.098304 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <cstdio>\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void maxi(int* a, int* b, int n)\n",
    "{\n",
    "    int block = 256 * blockIdx.x;\n",
    "    int max = 0;\n",
    "\n",
    "    for (int i = block; i < min(256 + block, n); i++) {\n",
    "\n",
    "        if (max < a[i]) {\n",
    "            max = a[i];\n",
    "        }\n",
    "    }\n",
    "    b[blockIdx.x] = max;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int n;\n",
    "    n = 3 << 2;\n",
    "    int a[n];\n",
    "\n",
    "    cout << \"Elements: \";\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        a[i] = rand() % n;\n",
    "        cout << a[i] << \"\\t\";\n",
    "    }\n",
    "\n",
    "    cudaEvent_t start, end;\n",
    "    int *ad, *bd;\n",
    "    int size = n * sizeof(int);\n",
    "    cudaMalloc(&ad, size);\n",
    "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
    "    int grids = ceil(n * 1.0f / 256.0f);\n",
    "    cudaMalloc(&bd, grids * sizeof(int));\n",
    "\n",
    "    dim3 grid(grids, 1);\n",
    "    dim3 block(1, 1);\n",
    "\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&end);\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    while (n > 1) {\n",
    "        maxi<<<grids, block>>>(ad, bd, n);\n",
    "        n = ceil(n * 1.0f / 256.0f);\n",
    "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(end);\n",
    "    cudaEventSynchronize(end);\n",
    "\n",
    "    float time = 0;\n",
    "    cudaEventElapsedTime(&time, start, end);\n",
    "\n",
    "    int ans[2];\n",
    "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cout << \"\\nThe largest element is: \" << ans[0] << endl;\n",
    "\n",
    "    cout << \"The time required: \" << time << \" seconds\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da51775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "fsharp",
    "items": [
     {
      "aliases": [],
      "name": "fsharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
